@inproceedings{Hashiguchi_2022_ACCVW_MSCA,
  author    = {Hashiguchi, Ryota and Tamaki, Toru},
  booktitle = {Proceedings of the Asian Conference on Computer Vision (ACCV) Workshops},
  month     = {December},
  pages     = {276-288},
  title     = {Temporal Cross-attention for Action Recognition},
  url       = {https://openaccess.thecvf.com/content/ACCV2022W/TCV/html/Hashiguchi_Temporal_Cross-attention_for_Action_Recognition_ACCVW_2022_paper.html},
  year      = {2022}
}

@article{Hashiguchi_arxiv2022_MSCA,
  author     = {Ryota Hashiguchi and
                Toru Tamaki},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2204-00452.bib},
  doi        = {10.48550/arXiv.2204.00452},
  eprint     = {2204.00452},
  eprinttype = {arXiv},
  journal    = {CoRR},
  timestamp  = {Wed, 06 Apr 2022 14:29:31 +0200},
  title      = {Vision Transformer with Cross-attention by Temporal Shift for Efficient
                Action Recognition},
  url        = {https://doi.org/10.48550/arXiv.2204.00452},
  volume     = {abs/2204.00452},
  year       = {2022}
}

@inproceedings{Kamiya_IWFCV2024_Multi_Model,
  author       = {Kodai Kamiya and Toru Tamaki},
  booktitle    = {The 30th International Workshop on Frontiers of Computer Vision (IW-FCV2024)},
  organization = {The Institute of Electrical Engineers of Japan},
  title        = {Multi-model learning by sequential reading of untrimmed videos for action recognition},
  url          = {https://www.scitepress.org/Link.aspx?doi=10.5220/0012310400003660},
  url          = {https://arxiv.org/abs/2401.14675},
  year         = {2024}
}

@inproceedings{Kimata_MMAsia2022_ObjectMix,
  address   = {New York, NY, USA},
  articleno = {26},
  author    = {Kimata, Jun and Nitta, Tomoya and Tamaki, Toru},
  booktitle = {Proceedings of the 4th ACM International Conference on Multimedia in Asia},
  doi       = {10.1145/3551626.3564941},
  isbn      = {9781450394789},
  keywords  = {action recognition, instance segmentation, data augmentation},
  location  = {Tokyo, Japan},
  numpages  = {7},
  publisher = {Association for Computing Machinery},
  series    = {MMAsia '22},
  title     = {ObjectMix: Data Augmentation by Copy-Pasting Objects in Videos for Action Recognition},
  url       = {https://doi.org/10.1145/3551626.3564941},
  year      = {2022}
}

@article{Nitta_IEICEED_2023_Object-ABN,
  author  = {Tomoya Nitta and
             Tsubasa Hirakawa and
             Hironobu Fujiyoshi and
             Toru Tamaki},
  doi     = {10.1587/transinf.2022EDP7138},
  journal = {IEICE Transactions on Information and Systems},
  number  = {3},
  pages   = {391-400},
  title   = {Object-ABN: Learning to Generate Sharp Attention Maps for Action Recognition},
  url     = {https://doi.org/10.1587/transinf.2022EDP7138},
  volume  = {E106.D},
  year    = {2023}
}

@article{Omi_IEICE-ED2022_MDL,
  author  = {Kazuki Omi and Jun Kimata and Toru Tamaki},
  doi     = {10.1587/transinf.2022EDP7058},
  journal = {IEICE Transactions on Information and Systems},
  number  = {12},
  pages   = {2119-2126},
  title   = {Model-Agnostic Multi-Domain Learning with Domain-Specific Adapters for Action Recognition},
  url     = {https://doi.org/10.1587/transinf.2022EDP7058},
  volume  = {E105-D},
  year    = {2022}
}

@inproceedings{Omi_IWAIT2022_ADDA,
  author    = {Kazuki Omi and Toru Tamaki},
  booktitle = {International Workshop on Advanced Imaging Technology (IWAIT) 2022},
  doi       = {10.1117/12.2625953},
  month     = {January},
  title     = {On the instability of unsupervised domain adaptation with ADDA},
  url       = {https://doi.org/10.1117/12.2625953},
  volume    = {121771X},
  year      = {2021}
}

@article{Otani_IEEEAccess2022_MPEG_JPEG,
  author    = {Aoi Otani and
               Ryota Hashiguchi and
               Kazuki Omi and
               Norishige Fukushima and
               Toru Tamaki},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/journals/access/OtaniHOFT22.bib},
  doi       = {10.1109/ACCESS.2022.3204755},
  journal   = {{IEEE} Access},
  pages     = {94898--94907},
  timestamp = {Sun, 02 Oct 2022 15:26:28 +0200},
  title     = {Performance Evaluation of Action Recognition Models on Low Quality
               Videos},
  url       = {https://doi.org/10.1109/ACCESS.2022.3204755},
  volume    = {10},
  year      = {2022}
}

@inproceedings{Shimizu_MVA2023_IV_ViT,
  author    = {Shimizu, Shuki and Tamaki, Toru},
  booktitle = {2023 18th International Conference on Machine Vision and Applications (MVA)},
  doi       = {10.23919/MVA57639.2023.10215661},
  keywords  = {Training;Image recognition;Machine vision;Transformers;Tuning;Videos},
  number    = {},
  pages     = {1-6},
  title     = {Joint learning of images and videos with a single Vision Transformer},
  url       = {https://ieeexplore.ieee.org/document/10215661},
  volume    = {},
  year      = {2023}
}
@inproceedings{Sugiura_VISAPP2024_S3Aug,
  author       = {Taiki Sugiura. and Toru Tamaki.},
  booktitle    = {Proceedings of the 19th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 2: VISAPP},
  doi          = {10.5220/0012310400003660},
  isbn         = {978-989-758-679-8},
  issn         = {2184-4321},
  organization = {INSTICC},
  pages        = {71-79},
  publisher    = {SciTePress},
  title        = {S3Aug: Segmentation, Sampling, and Shift for Action Recognition},
  url          = {https://www.scitepress.org/Link.aspx?doi=10.5220/0012310400003660},
  year         = {2024}
}
